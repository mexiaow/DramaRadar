#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from __future__ import annotations

import argparse
import gzip
import json
import os
import sqlite3
import sys
import time
import urllib.error
import urllib.request
from dataclasses import dataclass
from datetime import datetime
from html.parser import HTMLParser
from typing import Any, Optional
from zoneinfo import ZoneInfo


MAOYAN_URL = "https://piaofang.maoyan.com/web-heat"
MAOYAN_REFERER = "https://piaofang.maoyan.com/"
TZ_SHANGHAI = ZoneInfo("Asia/Shanghai")


@dataclass(frozen=True)
class DramaItem:
    name: str
    platform: str
    is_first_day: bool


class MaoyanWebHeatParser(HTMLParser):
    """
    è§£æçŒ«çœ¼ã€Œç½‘æ’­çƒ­åº¦ã€é¡µé¢ï¼šæå– .video-name ä¸ .web-infoã€‚
    é‡‡ç”¨æ ‡å‡†åº“ HTMLParserï¼Œé¿å…å¼•å…¥ç¬¬ä¸‰æ–¹ä¾èµ–ã€‚
    """

    def __init__(self) -> None:
        super().__init__(convert_charrefs=True)
        self._current: Optional[str] = None  # "name" | "info" | None
        self._buffer: list[str] = []
        self.names: list[str] = []
        self.infos: list[str] = []

    def handle_starttag(self, tag: str, attrs: list[tuple[str, Optional[str]]]) -> None:
        if tag != "p":
            return

        classes = ""
        for k, v in attrs:
            if k == "class" and v:
                classes = v
                break

        class_list = set(classes.split())
        if "video-name" in class_list:
            self._current = "name"
            self._buffer = []
        elif "web-info" in class_list:
            self._current = "info"
            self._buffer = []

    def handle_data(self, data: str) -> None:
        if self._current is None:
            return
        if data:
            self._buffer.append(data)

    def handle_endtag(self, tag: str) -> None:
        if tag != "p" or self._current is None:
            return

        text = " ".join("".join(self._buffer).split()).strip()
        if self._current == "name":
            if text:
                self.names.append(text)
        elif self._current == "info":
            # åŸå§‹ä¿¡æ¯ï¼šå¦‚â€œè…¾è®¯è§†é¢‘ç‹¬æ’­ ä¸Šçº¿8å¤©â€â€œèŠ’æœTVç‹¬æ’­ ä¸Šçº¿é¦–æ—¥â€
            self.infos.append(text)

        self._current = None
        self._buffer = []


def now_shanghai() -> datetime:
    return datetime.now(tz=TZ_SHANGHAI)


def shanghai_date_str(dt: datetime) -> str:
    return dt.strftime("%Y-%m-%d")


def shanghai_datetime_str(dt: datetime) -> str:
    return dt.strftime("%Y-%m-%d %H:%M:%S")


def read_json_file(path: str) -> dict[str, Any]:
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def load_config(config_path: str) -> dict[str, str]:
    cfg: dict[str, Any] = {}
    if os.path.exists(config_path):
        cfg = read_json_file(config_path)

    telegram = cfg.get("telegram", {}) if isinstance(cfg, dict) else {}
    bot_token = os.environ.get("TG_BOT_TOKEN") or telegram.get("botToken") or ""
    chat_id = os.environ.get("TG_CHAT_ID") or telegram.get("chatId") or ""

    return {"bot_token": str(bot_token), "chat_id": str(chat_id)}


def fetch_maoyan_html(timeout_sec: int = 15, retries: int = 3, verbose: bool = False) -> str:
    headers = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/122.0.0.0 Safari/537.36"
        ),
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Language": "zh-CN,zh;q=0.9",
        "Accept-Encoding": "gzip",
        "Referer": MAOYAN_REFERER,
    }

    last_error: Optional[BaseException] = None
    for attempt in range(1, retries + 1):
        try:
            req = urllib.request.Request(MAOYAN_URL, headers=headers, method="GET")
            with urllib.request.urlopen(req, timeout=timeout_sec) as resp:
                raw = resp.read()
                encoding = resp.headers.get("Content-Encoding", "")
                if encoding.lower() == "gzip":
                    raw = gzip.decompress(raw)
                return raw.decode("utf-8", errors="replace")
        except (urllib.error.URLError, TimeoutError, OSError) as e:
            last_error = e
            if verbose:
                print(f"[WARN] æŠ“å–å¤±è´¥ï¼ˆç¬¬{attempt}/{retries}æ¬¡ï¼‰ï¼š{e}", file=sys.stderr)
            if attempt < retries:
                time.sleep(0.8 * attempt)

    raise RuntimeError(f"æŠ“å–å¤±è´¥ï¼šå·²è€—å°½é‡è¯•æ¬¡æ•°ï¼›æœ€åé”™è¯¯ï¼š{last_error}")


def extract_platform(info: str) -> str:
    """
    ä»â€œå¹³å° + ä¸Šçº¿Xå¤©/é¦–æ—¥â€ä¸­æå–ç¨³å®šçš„â€œå¹³å°â€éƒ¨åˆ†ï¼Œé¿å…å¤©æ•°å¯¼è‡´æ¯æ—¥æ— æ„ä¹‰å˜åŒ–ã€‚
    """
    if not info:
        return ""
    idx = info.find("ä¸Šçº¿")
    base = info[:idx] if idx >= 0 else info
    return " ".join(base.split()).strip()


def is_first_day_info(info: str) -> bool:
    return "ä¸Šçº¿é¦–æ—¥" in (info or "")


def parse_drama_items(html: str) -> list[DramaItem]:
    parser = MaoyanWebHeatParser()
    parser.feed(html)

    if not parser.names:
        raise RuntimeError("æœªè§£æåˆ°ä»»ä½•ç‰‡åï¼šå¯èƒ½é¡µé¢ç»“æ„å·²å˜åŒ–æˆ–è¢«åçˆ¬æ‹¦æˆª")

    items: list[DramaItem] = []
    for i, name in enumerate(parser.names):
        raw_info = parser.infos[i] if i < len(parser.infos) else ""
        items.append(
            DramaItem(
                name=name,
                platform=extract_platform(raw_info),
                is_first_day=is_first_day_info(raw_info),
            )
        )

    # å»é‡ï¼šåŒååªä¿ç•™é¦–æ¬¡å‡ºç°çš„é‚£æ¡
    unique: dict[str, DramaItem] = {}
    for it in items:
        if it.name not in unique:
            unique[it.name] = it
    return list(unique.values())


def open_db(db_path: str) -> sqlite3.Connection:
    os.makedirs(os.path.dirname(db_path), exist_ok=True)
    conn = sqlite3.connect(db_path)
    conn.execute(
        """
        CREATE TABLE IF NOT EXISTS dramas (
          name TEXT PRIMARY KEY,
          first_seen TEXT NOT NULL,
          last_seen TEXT NOT NULL,
          last_info TEXT NOT NULL,
          source TEXT NOT NULL
        )
        """
    )
    conn.execute(
        """
        CREATE TABLE IF NOT EXISTS meta (
          key TEXT PRIMARY KEY,
          value TEXT NOT NULL
        )
        """
    )
    return conn


def open_db_readonly(db_path: str) -> sqlite3.Connection:
    # åªè¯»æ¨¡å¼ï¼šç”¨äº --dry-runï¼Œé¿å…åˆ›å»º/ä¿®æ”¹DBæ–‡ä»¶
    uri = f"file:{db_path}?mode=ro"
    return sqlite3.connect(uri, uri=True)


def db_is_empty(conn: sqlite3.Connection) -> bool:
    cur = conn.execute("SELECT COUNT(1) FROM dramas")
    count = int(cur.fetchone()[0])
    return count == 0


def db_insert_baseline(conn: sqlite3.Connection, items: list[DramaItem], dt: datetime) -> None:
    day = shanghai_date_str(dt)
    with conn:
        conn.executemany(
            """
            INSERT OR IGNORE INTO dramas(name, first_seen, last_seen, last_info, source)
            VALUES(?, ?, ?, ?, ?)
            """,
            [(it.name, day, day, it.platform, MAOYAN_URL) for it in items],
        )
        conn.execute(
            "INSERT OR REPLACE INTO meta(key, value) VALUES(?, ?)",
            ("last_run_at", dt.isoformat()),
        )


def db_find_new_items(conn: sqlite3.Connection, items: list[DramaItem]) -> list[DramaItem]:
    new_items: list[DramaItem] = []
    for it in items:
        cur = conn.execute("SELECT 1 FROM dramas WHERE name = ? LIMIT 1", (it.name,))
        if cur.fetchone() is None:
            new_items.append(it)
    return new_items


def db_upsert_items(conn: sqlite3.Connection, items: list[DramaItem], dt: datetime) -> None:
    day = shanghai_date_str(dt)
    with conn:
        for it in items:
            conn.execute(
                """
                INSERT INTO dramas(name, first_seen, last_seen, last_info, source)
                VALUES(?, ?, ?, ?, ?)
                ON CONFLICT(name) DO UPDATE SET
                  last_seen=excluded.last_seen,
                  last_info=CASE WHEN excluded.last_info != '' THEN excluded.last_info ELSE dramas.last_info END
                """,
                (it.name, day, day, it.platform, MAOYAN_URL),
            )
        conn.execute(
            "INSERT OR REPLACE INTO meta(key, value) VALUES(?, ?)",
            ("last_run_at", dt.isoformat()),
        )


def build_telegram_text(new_items: list[DramaItem], dt: datetime) -> str:
    lines: list[str] = [f"ğŸ¯ å‘ç°çŒ«çœ¼ç½‘æ’­çƒ­åº¦æ–°å‰§ï¼ˆ{len(new_items)}éƒ¨ï¼‰"]
    for it in new_items:
        if it.platform and it.is_first_day:
            lines.append(f"- {it.name}ï¼ˆ{it.platform}ï¼›ä¸Šçº¿é¦–æ—¥ï¼‰")
        elif it.platform:
            lines.append(f"- {it.name}ï¼ˆ{it.platform}ï¼‰")
        else:
            lines.append(f"- {it.name}")
    lines.append(f"æ¥æºï¼š{MAOYAN_URL}")
    lines.append(f"æ—¶é—´ï¼š{shanghai_datetime_str(dt)}")
    return "\n".join(lines)


def send_telegram_message(bot_token: str, chat_id: str, text: str, timeout_sec: int = 15) -> None:
    if not bot_token or not chat_id:
        raise RuntimeError("ç¼ºå°‘TGé…ç½®ï¼šè¯·è®¾ç½®TG_BOT_TOKEN/TG_CHAT_IDæˆ–åœ¨config/local.jsonä¸­é…ç½®")

    url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
    payload = json.dumps(
        {"chat_id": chat_id, "text": text, "disable_web_page_preview": True},
        ensure_ascii=False,
    ).encode("utf-8")

    req = urllib.request.Request(
        url,
        data=payload,
        headers={"Content-Type": "application/json"},
        method="POST",
    )
    try:
        with urllib.request.urlopen(req, timeout=timeout_sec) as resp:
            body = resp.read().decode("utf-8", errors="replace")
            if resp.status != 200:
                raise RuntimeError(f"TGå‘é€å¤±è´¥ï¼šHTTP {resp.status}ï¼š{body[:300]}")
    except urllib.error.HTTPError as e:
        detail = e.read().decode("utf-8", errors="replace")
        raise RuntimeError(f"TGå‘é€å¤±è´¥ï¼šHTTP {e.code}ï¼š{detail[:300]}") from e


def parse_args(argv: list[str]) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="çŒ«çœ¼ç½‘æ’­çƒ­åº¦æ–°å‰§ç›‘æ§ï¼ˆå‘ç°æ–°å‰§åTGæé†’ï¼‰")
    parser.add_argument("--dry-run", action="store_true", help="æ¼”ç»ƒæ¨¡å¼ï¼šä¸å†™DBã€ä¸å‘TG")
    parser.add_argument("--no-telegram", action="store_true", help="ä¸å‘é€TGï¼ˆä½†ä»æ›´æ–°DBï¼‰")
    parser.add_argument("--verbose", action="store_true", help="è¾“å‡ºæ›´å¤šæ—¥å¿—")
    parser.add_argument("--config-path", default=os.environ.get("DRAMARADAR_CONFIG_PATH", "config/local.json"))
    parser.add_argument("--db-path", default=os.environ.get("DRAMARADAR_DB_PATH", "data/maoyan_web_heat.sqlite3"))
    return parser.parse_args(argv)


def main(argv: list[str]) -> int:
    args = parse_args(argv)
    cfg = load_config(args.config_path)

    html = fetch_maoyan_html(verbose=bool(args.verbose))
    items = parse_drama_items(html)

    dt = now_shanghai()
    db_path = str(args.db_path)

    if args.dry_run and not os.path.exists(db_path):
        print(f"[DRY] é¦–æ¬¡è¿è¡Œå°†å»ºç«‹åŸºçº¿ï¼ˆ{len(items)}éƒ¨ï¼‰ï¼Œä¸åˆ›å»ºDBã€ä¸å†™å…¥ã€ä¸å‘é€TG")
        return 0

    conn: sqlite3.Connection
    if args.dry_run:
        conn = open_db_readonly(db_path)
    else:
        conn = open_db(db_path)

    try:
        if db_is_empty(conn):
            # é¦–æ¬¡è¿è¡Œï¼šå»ºç«‹â€œåŸºçº¿â€ï¼Œä¸æé†’ï¼ˆé¿å…æŠŠå­˜é‡å‰§é›†å½“æˆæ–°å‰§åˆ·å±ï¼‰
            if args.dry_run:
                print(f"[DRY] é¦–æ¬¡è¿è¡Œå°†å»ºç«‹åŸºçº¿ï¼ˆ{len(items)}éƒ¨ï¼‰ï¼Œä¸å†™å…¥ã€ä¸å‘é€TG")
                return 0
            db_insert_baseline(conn, items, dt)
            print(f"[OK] é¦–æ¬¡è¿è¡Œå·²å»ºç«‹åŸºçº¿ï¼ˆ{len(items)}éƒ¨ï¼‰ï¼Œæœªå‘é€TGæé†’ï¼›DBï¼š{db_path}")
            return 0

        new_items = db_find_new_items(conn, items)

        if args.dry_run:
            print(f"[DRY] æœ¬æ¬¡æŠ“å–åˆ° {len(items)} éƒ¨ï¼›æ–°å¢ {len(new_items)} éƒ¨ï¼›ä¸å†™å…¥ã€ä¸å‘é€TG")
            if new_items:
                print(build_telegram_text(new_items, dt))
            return 0

        if new_items and not args.no_telegram:
            text = build_telegram_text(new_items, dt)
            send_telegram_message(cfg["bot_token"], cfg["chat_id"], text)
            print("[OK] å·²å‘é€TGæé†’")
        elif new_items and args.no_telegram:
            print("[OK] æ£€æµ‹åˆ°æ–°å‰§ï¼Œä½†æŒ‰å‚æ•°è·³è¿‡TGå‘é€ï¼ˆ--no-telegramï¼‰")

        db_upsert_items(conn, items, dt)
        print(f"[OK] æœ¬æ¬¡æŠ“å–åˆ° {len(items)} éƒ¨ï¼›æ–°å¢ {len(new_items)} éƒ¨ï¼›DBï¼š{db_path}")
        return 0
    finally:
        conn.close()


if __name__ == "__main__":
    try:
        raise SystemExit(main(sys.argv[1:]))
    except Exception as e:
        print(f"[ERR] {e}", file=sys.stderr)
        raise SystemExit(1)
